import matplotlib.pyplot as plt
import torch
import torchvision
from torch import nn
from torchvision import transforms
from helper_functions import set_seeds
import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# Load pretrained ViT
pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT
pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)

# Freeze pretrained parameters
for parameter in pretrained_vit.parameters():
    parameter.requires_grad = False

# Define classes
class_names = ["fungal", "Healthy", "nutrition dificiency", "psoriasis"]

# Replace classification head
set_seeds()
pretrained_vit.heads = nn.Linear(in_features=768, out_features=len(class_names)).to(device)

# Verify trainable parameters
trainable_params = sum(p.numel() for p in pretrained_vit.parameters() if p.requires_grad)
total_params = sum(p.numel() for p in pretrained_vit.parameters())
print(f"Trainable parameters: {trainable_params:,} / {total_params:,}")

from torchinfo import summary
summary(model=pretrained_vit, 
        input_size=(32, 3, 224, 224), 
        col_names=["input_size", "output_size", "num_params", "trainable"],
        col_width=20,
        row_settings=["var_names"])

# Directories
train_dir = "dataset/train"
test_dir = "dataset/test"

# Get transforms
pretrained_vit_transforms = pretrained_vit_weights.transforms()
print(pretrained_vit_transforms)

NUM_WORKERS = os.cpu_count()

def create_dataloaders_with_validation(
    train_dir: str,
    test_dir: str,
    transform: transforms.Compose,
    batch_size: int,
    validation_split: float = 0.2,
    num_workers: int = NUM_WORKERS
):
    """
    Create train, validation, and test dataloaders.
    Splits training data into train and validation sets.
    """
    # Load full training dataset
    full_train_data = datasets.ImageFolder(train_dir, transform=transform)
    test_data = datasets.ImageFolder(test_dir, transform=transform)
    
    class_names = full_train_data.classes
    
    # Calculate split sizes
    total_train_size = len(full_train_data)
    val_size = int(total_train_size * validation_split)
    train_size = total_train_size - val_size
    
    # Split training data into train and validation
    train_data, val_data = random_split(
        full_train_data, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    print(f"\nDataset sizes:")
    print(f"  Training: {len(train_data)}")
    print(f"  Validation: {len(val_data)}")
    print(f"  Test: {len(test_data)}")
    
    # Create dataloaders
    train_dataloader = DataLoader(
        train_data,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
    )
    
    val_dataloader = DataLoader(
        val_data,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )
    
    test_dataloader = DataLoader(
        test_data,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )
    
    return train_dataloader, val_dataloader, test_dataloader, class_names

# Create dataloaders with validation split
train_dataloader, val_dataloader, test_dataloader, class_names = create_dataloaders_with_validation(
    train_dir=train_dir,
    test_dir=test_dir,
    transform=pretrained_vit_transforms,
    batch_size=32,
    validation_split=0.2  # 20% of training data for validation
)

# Setup training
optimizer = torch.optim.Adam(params=pretrained_vit.parameters(), lr=1e-4)  # Lower learning rate
loss_fn = torch.nn.CrossEntropyLoss()

# Import your engine module
from engine import engine

# Train with validation
pretrained_vit_results = engine.train(
    model=pretrained_vit,
    train_dataloader=train_dataloader,
    test_dataloader=val_dataloader,  # Use validation set during training
    optimizer=optimizer,
    loss_fn=loss_fn,
    epochs=30,
    device=device
)

# Save model (state_dict is better practice)
torch.save(pretrained_vit.state_dict(), 'model1.pth')
print("\nModel saved as model1.pth")

# Plot training and validation metrics in a single figure with 2 subplots
results = pretrained_vit_results

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Loss plot
ax1.plot(results['train_loss'], label='Training Loss', linewidth=2)
ax1.plot(results['test_loss'], label='Validation Loss', linewidth=2)
ax1.set_title('Loss Over Epochs', fontsize=12)
ax1.set_xlabel('Epoch', fontsize=10)
ax1.set_ylabel('Loss', fontsize=10)
ax1.legend(fontsize=10)
ax1.grid(True, alpha=0.3)
ax1.set_xlim(0, len(results['train_loss']))

# Accuracy plot
ax2.plot(results['train_acc'], label='Training Accuracy', linewidth=2)
ax2.plot(results['test_acc'], label='Validation Accuracy', linewidth=2)
ax2.set_title('Accuracy Over Epochs', fontsize=12)
ax2.set_xlabel('Epoch', fontsize=10)
ax2.set_ylabel('Accuracy', fontsize=10)
ax2.legend(fontsize=10)
ax2.grid(True, alpha=0.3)
ax2.set_xlim(0, len(results['train_acc']))

plt.tight_layout()
plt.show()

# ===== FINAL EVALUATION ON TEST SET =====
print("\n" + "="*50)
print("EVALUATING ON TEST SET")
print("="*50)

pretrained_vit.eval()

# Test set evaluation
test_loss = 0
test_correct = 0
test_total = 0
y_true_test = []
y_pred_test = []

with torch.no_grad():
    for images, labels in test_dataloader:
        images, labels = images.to(device), labels.to(device)
        outputs = pretrained_vit(images)
        
        # Calculate loss
        loss = loss_fn(outputs, labels)
        test_loss += loss.item()
        
        # Calculate accuracy
        preds = torch.argmax(outputs, dim=1)
        test_correct += (preds == labels).sum().item()
        test_total += labels.size(0)
        
        # Store for confusion matrix
        y_true_test.extend(labels.cpu().numpy())
        y_pred_test.extend(preds.cpu().numpy())

# Calculate metrics
test_loss /= len(test_dataloader)
test_acc = 100 * test_correct / test_total

print(f"\nTest Set Results:")
print(f"  Loss: {test_loss:.4f}")
print(f"  Accuracy: {test_acc:.2f}%")
print(f"  Correct: {test_correct}/{test_total}")

# Test set confusion matrix only
print("\n--- Test Set Confusion Matrix ---")
cm_test = confusion_matrix(y_true_test, y_pred_test)
print("Confusion Matrix:\n", cm_test)

# Plot confusion matrix with your exact styling
fig, ax = plt.subplots(figsize=(8, 8))
disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=class_names)
disp_test.plot(ax=ax, cmap=plt.cm.Blues, colorbar=True)
plt.title("Confusion Matrix", fontsize=14)
plt.tight_layout()
plt.show()
